# RAGWebApp

# Enhanced RAG System 

This project is an advanced Retrieval-Augmented Generation (RAG) system built with Streamlit, LangChain, and Ollama. It is allowing users to upload documents  and query them to get an accurate results based on the context of the uploaded document.

## üåü Features

- **RAG Functionality**: Use state-of-the-art language models for question answering.
- **Multiple Document Formats**: Supports PDF, DOCX, TXT, CSV, and PPTX.
- **Model Management**: Easily switch between different language models and embedding models.


## üöÄ Getting Started

### Prerequisites

- Python 3.8+
- Ollama installed and running
- Sufficient system resources for model execution

### Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/yourusername/enhanced-rag-system.git
   cd enhanced-rag-system

2. **Running the Application:
   ```bash
   ollama serve
   streamlit run app.py


### üíª Usage
Select Model:

Choose from installed Ollama models.
Select embedding model for document processing.
Upload Documents:

Upload documents to a collection.

Ask Questions:

Enter queries about your documents.
Get AI-generated responses based on document content.


Copyright (c) [2025] [Mohamed Shokir]

## Citation
If you use this code in your research, please cite it as:

Mohamed Shokir (2025). GitHub Repository. https://github.com/MohamedShokir/RAGWebApp.git

üôè Acknowledgments
LangChain community
Ollama developers
Streamlit team
Open source contributors
Last updated: 15/3/2025
