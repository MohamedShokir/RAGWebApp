# RAGWebApp

# Enhanced RAG System with Document Repository

This project is an advanced Retrieval-Augmented Generation (RAG) system built with Streamlit, LangChain, and Ollama. It features a persistent document repository, allowing users to upload documents once and query them anytime without re-uploading.

## üåü Features

- **Document Repository**: Store and manage documents in collections for persistent access.
- **RAG Functionality**: Use state-of-the-art language models for question answering.
- **Multiple Document Formats**: Supports PDF, DOCX, TXT, CSV, and PPTX.
- **Model Management**: Easily switch between different language models and embedding models.
- **Performance Monitoring**: Track system metrics and optimize performance.

## üöÄ Getting Started

### Prerequisites

- Python 3.8+
- Ollama installed and running
- Sufficient system resources for model execution

### Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/yourusername/enhanced-rag-system.git
   cd enhanced-rag-system

2. **Running the Application:
   ```bash
   ollama serve
   streamlit run app.py


### üì¶ Dependencies
Streamlit
LangChain
ChromaDB
Ollama
Sentence Transformers
Unstructured
Python-docx
PyPDF2
Docx2txt
Psutil
Pandas
Pdfminer.six

### üíª Usage
Select Model:

Choose from installed Ollama models.
Select embedding model for document processing.
Upload Documents:

Upload documents to a collection.
Documents are stored persistently.
Ask Questions:

Enter queries about your documents.
Get AI-generated responses based on document content.
Manage Repository:

View and manage document collections.
Clear collections when needed.



Copyright (c) [2025] [Mohamed Shokir]

## Citation
If you use this code in your research, please cite it as:

Mohamed Shokir (2025). GitHub Repository. https://github.com/MohamedShokir/RAGApp.git

üôè Acknowledgments
LangChain community
Ollama developers
Streamlit team
Open source contributors
Last updated: [Current Date]
